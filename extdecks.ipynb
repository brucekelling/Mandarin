{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cef3209-5a02-4cbc-abe8-6066fe680ea0",
   "metadata": {},
   "source": [
    "# Parse external pre-made decks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9466d9-639e-497c-9387-d4d4b2ba2edd",
   "metadata": {},
   "source": [
    "Note: needs external data in `downloads/`, won't be able to run without it. The outputs however are checked in to the repo, so you don't need to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2df4ae16-c1bd-495a-954e-e71ab9fd9592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob\n",
    "import pandas as pd\n",
    "from opencc import OpenCC\n",
    "\n",
    "def postprocess_chars(text):\n",
    "    mp = {\n",
    "        '…': '...',\n",
    "        '‘': \"'\",\n",
    "        '’': \"'\",\n",
    "        '“': '\"',\n",
    "        '”': '\"',\n",
    "    }\n",
    "    return ''.join(mp.get(c, c) for c in text)\n",
    "\n",
    "slides_df = pd.read_csv('data/slides.tsv', sep='\\t')\n",
    "assert list(slides_df.ID) == list(sorted(slides_df.ID))\n",
    "slides_t2s = slides_df.set_index('Traditional').Simplified.to_dict()\n",
    "slides_id2s = slides_df.set_index('ID').Simplified.to_dict()\n",
    "\n",
    "termid_df = pd.read_csv('data/term-ids.tsv', sep='\\t', comment='#')\n",
    "termid_df['Lesson'] = termid_df['ID'].str.slice(0, 5)\n",
    "termid_df['Lesson2'] = termid_df['ID'].str.extract('^(B.L..-II?)')\n",
    "lesson_trad_to_id = termid_df.set_index(['Lesson', 'Traditional']).ID.to_dict()\n",
    "lesson_pos_trad_to_id = termid_df.set_index(['Lesson', 'POS', 'Traditional']).ID.to_dict()\n",
    "lesson2_trad_to_id = termid_df.set_index(['Lesson2', 'Traditional']).ID.to_dict()\n",
    "lesson2_pos_trad_to_id = termid_df.set_index(['Lesson2', 'POS', 'Traditional']).ID.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c438c-4a90-4029-85a6-27e9a40636dd",
   "metadata": {},
   "source": [
    "## Quizlet deck\n",
    "\n",
    "* Official quizlet decks for B1-B4: https://quizlet.com/mtcbooktest/sets\n",
    "* Audio seems tts generated\n",
    "* Has images for ~600 slides, mostly from web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "846daf66-ede6-42aa-a00c-128fcaf8a22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trad \"臺灣 台灣\"\tsimp \"台湾\"\tslides \"?\"\n",
      "trad \"請進\"\tsimp \"请进\"\tslides \"?\"\n",
      "trad \"站\"\tsimp \"战\"\tslides \"站\"\n",
      "trad \"她\"\tsimp \"他\"\tslides \"她\"\n",
      "trad \"忘了\"\tsimp \"忘了\"\tslides \"?\"\n",
      "trad \"睡著\"\tsimp \"睡著\"\tslides \"睡着\"\n",
      "trad \"年年有餘\"\tsimp \"年年有馀\"\tslides \"年年有余\"\n",
      "trad \"義大利\"\tsimp \"意大利\"\tslides \"义大利\"\n",
      "trad \"捨不得\"\tsimp \"捨不得\"\tslides \"舍不得\"\n",
      "trad \"別的\"\tsimp \"別的\"\tslides \"别的\"\n",
      "trad \"台北101\"\tsimp \"台北101\"\tslides \"?\"\n",
      "trad \"2號線\"\tsimp \"2号线\"\tslides \"?\"\n",
      "trad \"照X光\"\tsimp \"照X光\"\tslides \"?\"\n",
      "trad \"中間商\"\tsimp \"中間商\"\tslides \"中间商\"\n",
      "trad \"經營\"\tsimp \"經營\"\tslides \"经营\"\n",
      "trad \"（台）斤\"\tsimp \"（台）斤\"\tslides \"?\"\n",
      "trad \"EMBA（高級管理人員工商管理碩士）\"\tsimp \"EMBA（高级管理人员工商管理硕士）\"\tslides \"?\"\n",
      "trad \"X分之Y\"\tsimp \"X分之Y\"\tslides \"?\"\n",
      "trad \"無人不知無人不曉\"\tsimp \"无人不知无人不晓\"\tslides \"?\"\n",
      "trad \"邱吉爾\"\tsimp \"邱吉尔\"\tslides \"丘吉尔\"\n",
      "trad \"一下...一下...\"\tsimp \"一下...一下...\"\tslides \"?\"\n",
      "trad \"就...而言\"\tsimp \"就...而言\"\tslides \"?\"\n",
      "trad \"是...的料\"\tsimp \"是...的料\"\tslides \"?\"\n",
      "trad \"在...之餘\"\tsimp \"在...之余\"\tslides \"?\"\n",
      "trad \"小自...大至...\"\tsimp \"小自...大至...\"\tslides \"?\"\n",
      "trad \"以...為...\"\tsimp \"以...为...\"\tslides \"?\"\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    'downloads/flashcards/quizlet.txt',  # quizlet-to-anki scraped notes exported to .txt\n",
    "    comment='#',\n",
    "    names=['Front', 'FrontAudio', 'Back', 'BackAudio', 'Image', 'AddRev', 'Tags'],\n",
    "    sep='\\t'\n",
    ")\n",
    "\n",
    "del df['FrontAudio']\n",
    "del df['BackAudio']\n",
    "del df['AddRev']\n",
    "del df['Image']\n",
    "\n",
    "df['Lesson'] = df['Tags'].str.replace('B0', 'B').str.replace(' ', '')\n",
    "assert all(re.match('^B[1-6]L[0-1][0-9]$', s) for s in df.Lesson)\n",
    "del df['Tags']\n",
    "\n",
    "OVERRIDES = {\n",
    "  'KTV': ['KTV', 'KTV'],\n",
    "  '故宮博物院（故宮）（故宫博物院（故宮））': ['故宮博物院（故宮）', '故宫博物院（故宫）'],  # 宮->宫\n",
    "  '公共汽車（公車）（公共汽车（公车））': ['公共汽車（公車）', '公共汽车（公车）'],\n",
    "  '星期（星期）<br>+number': ['星期 + number', '星期 + number'],\n",
    "  '女（女）<br>+noun': ['女 + noun', '女 + noun'],\n",
    "  'number+<br>月（月）': ['number + 月', 'number + 月'],\n",
    "  'number+<br>號（号）': ['number + 號', 'number + 号'],\n",
    "  '男（男）<br>+noun': ['男 + noun', '男 + noun'],\n",
    "  '師大（師範大學）（师大（师范大学））': ['師大（師範大學）', '师大（师范大学）'],\n",
    "  '待遇（待遇': ['待遇', '待遇'],\n",
    "  '貨比三家不吃虧<br>（货比三家不吃亏）': ['貨比三家不吃虧', '货比三家不吃亏'],\n",
    "  '(台)斤<br>（(台)斤）': ['（台）斤', '（台）斤'],\n",
    "  'EMBA(高級管理人員工商管理碩士)<br>（EMBA(高级管理<br>人员工商<br>管理硕士)）': ['EMBA（高級管理人員工商管理碩士）', 'EMBA（高级管理人员工商管理硕士）'],\n",
    "  '科系（科系': ['科系', '科系'],\n",
    "  '提不起（勇氣）（提不起（勇气））': ['提不起（勇氣）', '提不起（勇气）'],\n",
    "  '企業管理系(企管系)（企业管理系(企管系)）': ['企業管理系（企管系）', '企业管理系（企管系）'],\n",
    "}\n",
    "\n",
    "trad_col = []\n",
    "simp_col = []\n",
    "\n",
    "for k, text in enumerate(df.Front):\n",
    "    assert '\\n' not in text\n",
    "    text_orig = text\n",
    "    #text = re.sub(r'\\s*<br>\\s*', '\\n', text).strip()\n",
    "    if text in OVERRIDES:\n",
    "        trad, simp = OVERRIDES[text]\n",
    "    else:\n",
    "        if re.search('[-+`<>,()&\\'\"]', text) or text.count('（') != 1 or text.count('）') != 1:\n",
    "            print(\"  '%s': ['', ''],\" % text)\n",
    "        m = re.match('^(.+)[（](.+)[）]$', text)\n",
    "        assert m, text\n",
    "        trad, simp = m[1].strip(), m[2].strip()\n",
    "    #assert text.count('<') == 0, text\n",
    "\n",
    "    trad_col.append(trad)\n",
    "    simp_col.append(simp)\n",
    "\n",
    "    if trad not in slides_t2s or simp != slides_t2s[trad]:\n",
    "        print('trad \"%s\"\\tsimp \"%s\"\\tslides \"%s\"' % (trad, simp, slides_t2s.get(trad, '?')))\n",
    "\n",
    "df['Traditional'] = trad_col\n",
    "df['Simplified'] = simp_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d548e60-f726-4557-aa4f-e7c1ed9180cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dups in ['B4L02-II-26' 'B1L12-II-05']\n",
      "3073\n"
     ]
    }
   ],
   "source": [
    "QUIZLET_POS_MAP = {\n",
    "  '(N)': 'N',\n",
    "  '(V)': 'V',\n",
    "  '(Vst)': 'Vst',\n",
    "  '(Ptc)': 'Ptc',\n",
    "  '(Det)': 'Det',\n",
    "  '(Vs)': 'Vs',\n",
    "  '(Adv)': 'Adv',\n",
    "  '(Vaux)': 'Vaux',\n",
    "  '(Vi)': 'Vi',\n",
    "  '(Vs-pred)': 'Vs-pred',\n",
    "  '(V-sep)': 'V-sep',\n",
    "  '(M)': 'M',\n",
    "  '(Conj)': 'Conj',\n",
    "  'Adv': 'Adv',\n",
    "  'N': 'N',\n",
    "  'V': 'V',\n",
    "  'M': 'M',\n",
    "  'Vs': 'Vs',\n",
    "  'Vs-attr': 'Vs-attr',\n",
    "  'Prep': 'Prep',\n",
    "  'Ptc': 'Ptc',\n",
    "  'Vaux': 'Vaux',\n",
    "  'V-sep': 'V-sep',\n",
    "  'Det': 'Det',\n",
    "  'Vst': 'Vst',\n",
    "  '(Prep)': 'Prep',\n",
    "  '(Vp)': 'Vp',\n",
    "  '(Ptc': 'Ptc',\n",
    "  '(Vpt)': 'Vpt',\n",
    "  '(Vp-sep)': 'Vp-sep',\n",
    "  '(Vs-attr)': 'Vs-attr',\n",
    "  '(Vi, N)': 'N/Vi',  #1\n",
    "  '(Vs-sep)': 'Vs-sep',\n",
    "  '(Vi, V)': 'V/Vi', #1\n",
    "  '(V': 'V',\n",
    "  '(N/V)': 'N/V', #10\n",
    "  '(V/N)': 'V/N', #9\n",
    "  '(N/Vi)': 'N/Vi',\n",
    "  '9N)': 'N',\n",
    "}\n",
    "\n",
    "pinyin_col = []\n",
    "pos_col = []\n",
    "def_col = []\n",
    "\n",
    "for k, text in enumerate(df.Back):\n",
    "    assert '\\n' not in text\n",
    "    text_orig = text\n",
    "    text = text.replace('zhōngjiān<br>shāng<br>(N)', 'zhōngjiānshāng<br>(N)')\n",
    "    text = text.replace('xiónghuáng jiǔ<br>', 'xiónghuáng jiǔ<br><br>')\n",
    "    text = re.sub(r'\\s*<br>\\s*', '\\n', text).strip()\n",
    "    assert text.count('&') == 0 or 'Bed & Breakfast' in text\n",
    "    assert text.count('<') == 0, text\n",
    "    lines = text.split('\\n')\n",
    "    assert len(lines) >= 2, text_orig\n",
    "\n",
    "    if lines[1] != '' and lines[1] not in QUIZLET_POS_MAP:\n",
    "        print(text_orig)\n",
    "    #if len(lines) >= 4: print(text_orig)\n",
    "\n",
    "    pinyin = lines[0]\n",
    "    pinyin = pinyin.replace('ă', 'ǎ')\n",
    "    pinyin_col.append(pinyin)\n",
    "\n",
    "    pos_col.append(QUIZLET_POS_MAP.get(lines[1], ''))\n",
    "    def_col.append(' '.join(lines[2:]).strip())\n",
    "\n",
    "df['Pinyin'] = pinyin_col\n",
    "df['POS'] = pos_col\n",
    "df['Meaning'] = def_col\n",
    "\n",
    "id_col = []\n",
    "for row in df.itertuples():\n",
    "    key = (row.Lesson, row.POS, row.Traditional)\n",
    "    if key in lesson_pos_trad_to_id:\n",
    "        id_col.append(lesson_pos_trad_to_id[key])\n",
    "        continue\n",
    "    id_col.append(lesson_trad_to_id[(row.Lesson, row.Traditional)])\n",
    "df['ID'] = id_col\n",
    "df = df.sort_values('ID').reset_index(drop=True).copy()\n",
    "\n",
    "if len(set(df.ID)) != len(df):\n",
    "    dup_ids = df.ID.value_counts()[lambda X: X >= 2].index\n",
    "    print('dups in', dup_ids.values)\n",
    "    for term_id in dup_ids:\n",
    "        drop_idx = df[df.ID == term_id].index[-1]\n",
    "        df = df[df.index != drop_idx]\n",
    "\n",
    "df['Tags'] = ''\n",
    "df = df[['ID', 'Traditional', 'Simplified', 'Pinyin', 'POS', 'Meaning', 'Tags']].copy()\n",
    "df.to_csv('data/quizlet.tsv', index=False, sep='\\t')\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff7f32-3327-4cca-a7db-e5f1ad771936",
   "metadata": {},
   "source": [
    "# mquizlet\n",
    "\n",
    "* Source: https://quizlet.com/Michael5739/sets\n",
    "* Seems to have been manually typed from the book, lots of diffs vs slides, but good as an independent source for verification.\n",
    "* Has almost all of book 6, including B6L1-III missing in slides.\n",
    "* Missing B6L4-III, B6L10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c14587d-d422-4b2c-be11-bcaf3448ce38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dup: {'ID': 'B4L01-II-28', 'Traditional': '心理', 'Pinyin': 'xīnlǐ', 'POS': 'N', 'Meaning': 'psychological, mental'}\n",
      "unmerged: B4L07-I\t\t以下...以下...\tyǐxià... yǐxia...\tmeasure phrase, describing fast-changing alternating scenes of two activities\n",
      "dup: {'ID': 'B6L01-II-22', 'Traditional': '傾銷', 'Pinyin': 'qīngxiāo', 'POS': 'V', 'Meaning': 'to dump (products)'}\n",
      "dup: {'ID': 'B6L09-I-0-05', 'Traditional': '遷移', 'Pinyin': 'qiānyí', 'POS': 'Vi', 'Meaning': 'to move (forward)'}\n",
      "3538\n"
     ]
    }
   ],
   "source": [
    "POS_MAP = {\n",
    "  'Adv': 'Adv',\n",
    "  'Adv/N': 'Adv/N',\n",
    "  'Adv/Vs': 'Adv/Vs',\n",
    "  'Av': 'Adv',\n",
    "  'Conj': 'Conj',\n",
    "  'Det': 'Det',\n",
    "  'Id': 'Id',\n",
    "  'M': 'M',\n",
    "  'N': 'N',\n",
    "  'N, Vs': 'N/Vs',\n",
    "  'N/V': 'N/V',\n",
    "  'N/Vi': 'N/Vi',\n",
    "  'N/Vst': 'N/Vst',\n",
    "  'Nl': 'N',\n",
    "  'PH': 'Ph',\n",
    "  'Ph': 'Ph',\n",
    "  'Prep': 'Prep',\n",
    "  'Ptc': 'Ptc',\n",
    "  'V': 'V',\n",
    "  'V-sep': 'V-sep',\n",
    "  'V/': 'V/N', #jiàodǎo\n",
    "  'V/N': 'V/N',\n",
    "  'Vaux': 'Vaux',\n",
    "  'Vi': 'Vi',\n",
    "  'Vi/N': 'Vi/N',\n",
    "  'Vp': 'Vp',\n",
    "  'Vp-sep': 'Vp-sep',\n",
    "  'Vpt': 'Vpt',\n",
    "  'Vs': 'Vs',\n",
    "  'Vs-attr': 'Vs-attr',\n",
    "  'Vs-sep': 'Vs-sep',\n",
    "  'Vs/Adv': 'Vs/Adv',\n",
    "  'Vs/N': 'Vs/N',\n",
    "  'Vst': 'Vst',\n",
    "  'Vst/N': 'Vst/N',\n",
    "}\n",
    "\n",
    "slides_df['Lesson2'] = slides_df['ID'].str.extract('^(B.L..-II?)')\n",
    "lesson2_pinyin_to_id = slides_df.set_index(['Lesson2', 'Pinyin']).ID.to_dict()\n",
    "rows = []\n",
    "term_ids = set()\n",
    "\n",
    "for filepath in sorted(glob.glob('downloads/flashcards/mquizlet/B*')):  # copy pasted text from web pages\n",
    "    m = re.match('B([0-9])L([0-9]+)+[AD]([123])$', os.path.basename(filepath))\n",
    "    assert m, filepath\n",
    "    lesson = 'B%dL%.2d-%s' % (int(m[1]), int(m[2]), 'I' * int(m[3]))\n",
    "    lesson = lesson.replace('B6L81', 'B6L08')\n",
    "    lesson = lesson.replace('B6L89', 'B6L09')\n",
    "\n",
    "    lines = open(filepath).read().strip().split('\\n')\n",
    "    lines = [s.strip() for s in lines]\n",
    "    s = [i for i,x in enumerate(lines) if x.strip() == 'Original'][0]\n",
    "    t = [i for i,x in enumerate(lines) if x.startswith('About us')][0]\n",
    "    lines = lines[s+1:t]\n",
    "    lines = '\\n'.join(lines).strip()\n",
    "    lines = re.sub('\\n\\n+', '\\n\\n', lines)\n",
    "\n",
    "    for card in lines.split('\\n\\n'):\n",
    "        assert card.count('\\n') == 1\n",
    "        hanzi, text = card.split('\\n')\n",
    "        if ';' not in text: continue\n",
    "        pinyin, text = text.split(';', maxsplit=1)\n",
    "        pinyin = pinyin.strip()\n",
    "        text = text.strip()\n",
    "        pos = ''\n",
    "        tag = ''\n",
    "\n",
    "        if ';' in text:\n",
    "            x, y = text.split(';', maxsplit=1)\n",
    "            x = x.strip()\n",
    "            if x in POS_MAP:\n",
    "                pos = POS_MAP[x]\n",
    "                text = y\n",
    "        if pos == '':\n",
    "            for pref in POS_MAP.keys():\n",
    "                if text.startswith(pref + ' ') or  text.startswith(pref + ','):\n",
    "                    pos = POS_MAP[pref]\n",
    "                    text = text[len(pref)+1:]\n",
    "\n",
    "        text = text.strip()\n",
    "\n",
    "        # correct some systematic diffs\n",
    "        text = text.replace('(literally ', '(lit.')\n",
    "        text = text.replace('(literally, ', '(lit. ')\n",
    "        text = text.replace('(literally)', '(lit.)')\n",
    "        for x, y in ['説說', '内內', '麽麼', '爲為', '强強', '衆眾', '(（', ')）']:\n",
    "            hanzi = hanzi.replace(x, y)\n",
    "\n",
    "        key = (lesson, pos, hanzi)\n",
    "        key2 = (lesson[:5], hanzi)\n",
    "        key3 = (lesson, pinyin)\n",
    "        if key in lesson2_pos_trad_to_id:\n",
    "            term_id = lesson2_pos_trad_to_id[key]\n",
    "        elif key2 in lesson_trad_to_id:\n",
    "            term_id = lesson_trad_to_id[key2]\n",
    "        elif key3 in lesson2_pinyin_to_id:\n",
    "            term_id = lesson2_pinyin_to_id[key3]\n",
    "            tag = 'FlaggedTrad'\n",
    "        else:\n",
    "            print('unmerged: %s' % '\\t'.join((lesson, pos, hanzi, pinyin, text)))\n",
    "            continue\n",
    "\n",
    "        row = {\n",
    "            'ID': term_id,\n",
    "            'Traditional': hanzi,\n",
    "            'Pinyin': pinyin,\n",
    "            'POS': pos,\n",
    "            'Meaning': text,\n",
    "        }\n",
    "\n",
    "        if term_id in term_ids:\n",
    "            print('dup: %s' % row)\n",
    "            continue\n",
    "\n",
    "        rows.append(row)\n",
    "        term_ids.add(term_id)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv('data/mquizlet.tsv', sep='\\t', index=False)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5534cfd-4e1f-4edb-a96d-cae540c7898f",
   "metadata": {},
   "source": [
    "## jiru\n",
    "\n",
    "* \"A Course in Contemporary Chinese (當代中文課程) all vocabs audio\" deck:\n",
    "  * https://ankiweb.net/shared/info/2118503187\n",
    "  * https://github.com/jiru/ccc\n",
    "* High quality, fairly clean source, a little edited from the book\n",
    "* Some extra People and Place tags, but incomplete and not very useful\n",
    "* Real recorded audio extracts\n",
    "* B6 missing except for B6L01-I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4685ee03-713a-4e69-8516-7a9bef6cd15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4039\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    'downloads/flashcards/anki-2118503187.txt',\n",
    "    comment='#',\n",
    "    names=['Traditional', 'Pinyin', 'Meaning', 'POS', 'Lesson', 'Audio', 'Tags'],\n",
    "    sep='\\t',\n",
    "    index_col=False,\n",
    ")\n",
    "\n",
    "id_col = []\n",
    "for row in df.itertuples():\n",
    "    key2 = (row.Lesson, row.POS, row.Traditional)\n",
    "    if key2 in lesson2_pos_trad_to_id:\n",
    "        id_col.append(lesson2_pos_trad_to_id[key2])\n",
    "        continue\n",
    "    key = (row.Lesson[:5], row.Traditional)\n",
    "    id_col.append(lesson_trad_to_id[key])\n",
    "df['ID'] = id_col\n",
    "\n",
    "df['Meaning'] = [postprocess_chars(s) for s in df.Meaning]\n",
    "\n",
    "df['Tags'] = df.Tags.str.extract('(People|Place)').fillna('')\n",
    "df = df[['ID', 'Traditional', 'Pinyin', 'POS', 'Meaning', 'Tags', 'Audio']].copy()\n",
    "df.to_csv('data/ankiweb.tsv', index=False, sep='\\t')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1827869-69f3-45cd-bb69-b0d797d4b96d",
   "metadata": {},
   "source": [
    "## DDSG deck\n",
    "\n",
    "* From \"Dangdai Study Guide\": https://ddstudyguide.com/mediawiki/resources/assets/ddsg.apkg\n",
    "* Based off extracted text from slides, but lowest quality / highest diffs, many unwarranted extra remarks/rewordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35080e8f-a23a-4bcd-98f3-06c9809e41bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3855\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    'downloads/flashcards/ddsg.txt',\n",
    "    comment='#',\n",
    "    names=['Meaning', 'Pinyin', 'Unused', 'Traditional', 'Lesson', 'UnusedTags'],\n",
    "    sep='\\t',\n",
    "    index_col=False,\n",
    ")\n",
    "\n",
    "df['Lesson'] = ['B%sL%s-%s' % re.match('^Book([0-9])/Chapter([0-9]{2})-(I|II)$', s).groups() for s in df['Lesson']]\n",
    "df['Traditional'] = df.Traditional.str.extract('^<div><p><span style=\"?font-size:32px\"?>([^<]+)</span></p></div>$')\n",
    "assert sum(df.Traditional.isnull()) == 0\n",
    "assert sum(df.Lesson.isnull()) == 0\n",
    "\n",
    "POS_MAP = {\n",
    "  '(N)': 'N',\n",
    "  '(V)': 'V',\n",
    "  '(Vst)': 'Vst',\n",
    "  '(Ptc)': 'Ptc',\n",
    "  '(Det)': 'Det',\n",
    "  '(Vs)': 'Vs',\n",
    "  '(Adv)': 'Adv',\n",
    "  '(Vaux)': 'Vaux',\n",
    "  '(Vi)': 'Vi',\n",
    "  '(Vs-pred)': 'Vs-pred',\n",
    "  '(V-sep)': 'V-sep',\n",
    "  '(M)': 'M',\n",
    "  '(Conj)': 'Conj',\n",
    "  '(Prep)': 'Prep',\n",
    "  '(Vp)': 'Vp',\n",
    "  '(Ptc': 'Ptc',\n",
    "  '(Vpt)': 'Vpt',\n",
    "  '(Vp-sep)': 'Vp-sep',\n",
    "  '(Vs-attr)': 'Vs-attr',\n",
    "  '(Vi, N)': 'N/Vi',\n",
    "  '(Vs-sep)': 'Vs-sep',\n",
    "  '(Vi, V)': 'V/Vi',\n",
    "  '(V/N)': 'V/N',\n",
    "  '(N/V)': 'N/V',\n",
    "  '(V/N)': 'V/N',\n",
    "  '(N/Vi)': 'N/Vi',\n",
    "  '(V ': 'V',\n",
    "\n",
    "  '(Id)': 'Id',\n",
    "  '(Ph)': 'Ph',\n",
    "  '(Adv/N)': 'Adv/N',\n",
    "  '(N/Vst)': 'N/Vst',\n",
    "  '(Vst/N)': 'Vst/N',\n",
    "  '(Vi/N)': 'Vi/N',\n",
    "  '(Vs/N)': 'Vs/N',\n",
    "  '(N,V)': 'N/V',\n",
    "  'Adv ': 'Adv',\n",
    "  'N ': 'N',\n",
    "  'IDIOM&nbsp;': 'Id',\n",
    "}\n",
    "\n",
    "text_col = []\n",
    "pos_col = []\n",
    "\n",
    "for text in df.Meaning:\n",
    "    text = text.strip()\n",
    "    pos = ''\n",
    "    for pref in POS_MAP.keys():\n",
    "        if text.startswith(pref):\n",
    "            pos = POS_MAP[pref]\n",
    "            text = text[len(pref):].strip()\n",
    "            break\n",
    "    pos = pos.strip()\n",
    "\n",
    "    text = re.sub('^· ', '', text).strip()\n",
    "    text = text.replace(' ( ', ' (')\n",
    "    text = text.replace(' ) ', ') ')\n",
    "    text = postprocess_chars(text)\n",
    "\n",
    "    pos_col.append(pos)\n",
    "    text_col.append(text)\n",
    "\n",
    "df['Meaning'] = text_col\n",
    "df['POS'] = pos_col\n",
    "\n",
    "id_col = []\n",
    "for row in df.itertuples():\n",
    "    key2 = (row.Lesson, row.POS, row.Traditional)\n",
    "    if key2 in lesson2_pos_trad_to_id:\n",
    "        id_col.append(lesson2_pos_trad_to_id[key2])\n",
    "        continue\n",
    "    key = (row.Lesson[:5], row.Traditional)\n",
    "    term_id = lesson_trad_to_id[key]\n",
    "    assert term_id, key\n",
    "    id_col.append(term_id)\n",
    "df['ID'] = id_col\n",
    "\n",
    "df = df[['ID', 'Traditional', 'Pinyin', 'POS', 'Meaning']].copy()\n",
    "df.to_csv('data/ddsg.tsv', sep='\\t', index=False)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5a2eb1-c5e9-44b4-96be-022069d3ace2",
   "metadata": {},
   "source": [
    "# ccc-flashcards\n",
    "\n",
    "* Source: https://github.com/kevinlang/ccc-flashcards/blob/master/a_course_in_contemporary_chinese.tsv\n",
    "* https://www.plecoforums.com/threads/flashcards-for-a-course-in-contemporary-chinese.6100/\n",
    "* Quality mid way, some weird characters: trailing 's, non standard tone marks chars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f9b7cd2-96d1-4235-b4ae-48a5bb081ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4035\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for line in open('downloads/flashcards/ccc-flashcards.tsv'):\n",
    "    if line.startswith('//'):\n",
    "        m = re.match('//當代中文/Book ([1-6])/(L[0-9][0-9]-II?)$', line.strip())\n",
    "        assert m, line\n",
    "        lesson = 'B%s%s' % (m[1], m[2])\n",
    "        continue\n",
    "\n",
    "    assert len(line.split('\\t')) == 3, line.split('\\t')\n",
    "    line = line.rstrip('\\r\\n').split('\\t')\n",
    "    assert len(line) == 3\n",
    "    hanzi = line[0].strip()\n",
    "    pinyin = line[1].strip()\n",
    "    text = line[2].strip()\n",
    "\n",
    "    # incorrect lookalike chars in some terms\n",
    "    for x, y in [('é','é'), ('ù','ù'), ('ì','ì'), ('ǎ','ǎ'), ('à', 'à'), ('ǐ', 'ǐ'), ('í', 'í'), ('ū', 'ū'),\n",
    "                 ('á','á'), ('ē', 'ē'), ('ǔ', 'ǔ'), ('ǜ', 'ǜ'), ('ú', 'ú'), ('ā', 'ā'), ('ī', 'ī')\n",
    "                ]:\n",
    "        #if rows == []: print(x, end='')\n",
    "        pinyin = pinyin.replace(x, y)\n",
    "        text = text.replace(x, y)\n",
    "\n",
    "    text = text.replace(' ( ', ' (')\n",
    "    text = text.replace(' ) ', ') ')\n",
    "    text = postprocess_chars(text)\n",
    "\n",
    "    pos = ''\n",
    "    for pref in POS_MAP.keys():\n",
    "        if text.startswith(pref):\n",
    "            pos = POS_MAP[pref]\n",
    "            text = text[len(pref):].strip()\n",
    "            break\n",
    "    pos = pos.strip()\n",
    "    #if pos == '': print(line[-1])\n",
    "\n",
    "    key = (lesson[:5], hanzi)\n",
    "    key2 = (lesson, pos, hanzi)\n",
    "    if key2 in lesson2_pos_trad_to_id:\n",
    "        term_id = lesson2_pos_trad_to_id[key2]\n",
    "    else:\n",
    "        term_id = lesson_trad_to_id[key]\n",
    "    assert term_id\n",
    "\n",
    "    rows.append({\n",
    "        'ID': term_id,\n",
    "        'Traditional': hanzi,\n",
    "        'Pinyin': pinyin,\n",
    "        'POS': pos,\n",
    "        'Meaning': text\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv('data/ccc.tsv', sep='\\t', index=False)\n",
    "print(len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
